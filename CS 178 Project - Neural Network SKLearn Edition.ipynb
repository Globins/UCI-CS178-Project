{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Neural networks. The key to learning a good NN model on these data will be to ensure that your training algorithm does not become trapped in poor local optima. You should monitor its performance across backpropagation iterations on training/validation data, and verify that predictive performance improves to reasonable values. Start with few layers (2-3) and moderate numbers of hidden nodes (100-1000) per layer, and verify improvements over baseline linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mltools as ml\n",
    "from numpy import atleast_2d as twod\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('Data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('Data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xte,Ytr,Yte = ml.splitData(X,Y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtr)\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xte = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TAKES AROUND 1-2 HOURS TO RUN:\n",
    "reg = MLPClassifier(activation='tanh',\n",
    "                    solver='adam', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(250, 500, 250, 100), \n",
    "                    random_state=1,\n",
    "                    max_iter=500)\n",
    "reg.out_activation_ = 'softmax'\n",
    "AUC Score: .74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPClassifier(activation='tanh',\n",
    "                    solver='adam', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(250, 500, 250, 100), \n",
    "                    random_state=1,\n",
    "                    max_iter=500)\n",
    "reg.out_activation_ = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Neural Network training finished, took 1645.5158784389496 seconds\n"
     ]
    }
   ],
   "source": [
    "starting_time = time.time()\n",
    "reg.fit(Xtr, Ytr)\n",
    "end_time = time.time()\n",
    "print(\"Neural Network training finished, took {} seconds\".format(end_time - starting_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(X, Y):\n",
    "    try:                  # compute 'response' (soft binary classification score)\n",
    "        soft = reg.predict_proba(X)[:,1]  # p(class = 2nd)\n",
    "    except (AttributeError, IndexError):  # or we can use 'hard' binary prediction if soft is unavailable\n",
    "        soft = reg.predict(X)\n",
    "\n",
    "    n,d = twod(soft).shape             # ensure soft is the correct shape\n",
    "    soft = soft.flatten() if n==1 else soft.T.flatten()\n",
    "\n",
    "    indices = np.argsort(soft)         # sort data by score value\n",
    "    Y = Y[indices]\n",
    "    sorted_soft = soft[indices]\n",
    "\n",
    "    # compute rank (averaged for ties) of sorted data\n",
    "    dif = np.hstack( ([True],np.diff(sorted_soft)!=0,[True]) )\n",
    "    r1  = np.argwhere(dif).flatten()\n",
    "    r2  = r1[0:-1] + 0.5*(r1[1:]-r1[0:-1]) + 0.5\n",
    "    rnk = r2[np.cumsum(dif[:-1])-1]\n",
    "\n",
    "    # number of true negatives and positives\n",
    "    n0,n1 = sum(Y == 0), sum(Y == 1)\n",
    "\n",
    "    if n0 == 0 or n1 == 0:\n",
    "        raise ValueError('Data of both class values not found')\n",
    "\n",
    "    # compute AUC using Mann-Whitney U statistic\n",
    "    result = (np.sum(rnk[Y == 1]) - n1 * (n1 + 1.0) / 2.0) / n1 / n0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9784186344578066"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7188798912111473"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(Xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xleader = np.genfromtxt('Data/X_test.txt', delimiter=None)\n",
    "Xleader = scaler.transform(Xleader)\n",
    "predict_test = reg.predict_proba(Xleader)\n",
    "Yte = np.vstack((np.arange(Xleader.shape[0]), predict_test[:,1])).T\n",
    "np.savetxt('Y_submit.txt',Yte,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
