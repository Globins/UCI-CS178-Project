{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Neural networks. The key to learning a good NN model on these data will be to ensure that your training algorithm does not become trapped in poor local optima. You should monitor its performance across backpropagation iterations on training/validation data, and verify that predictive performance improves to reasonable values. Start with few layers (2-3) and moderate numbers of hidden nodes (100-1000) per layer, and verify improvements over baseline linear models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import mltools as ml\n",
    "from numpy import atleast_2d as twod\n",
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sklearn.set_config(working_memory=4096)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.genfromtxt('Data/X_train.txt', delimiter=None)\n",
    "Y = np.genfromtxt('Data/Y_train.txt', delimiter=None)\n",
    "X,Y = ml.shuffleData(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtr,Xte,Ytr,Yte = ml.splitData(X,Y, 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(Xtr)\n",
    "Xtr = scaler.transform(Xtr)\n",
    "Xte = scaler.transform(Xte)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "TAKES AROUND 2-4 HOURS TO RUN:\n",
    "reg = MLPClassifier(activation='relu',\n",
    "                    solver='adam', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(250, 350, 125, 50), \n",
    "                    random_state=1,\n",
    "                    max_iter=500)\n",
    "reg.out_activation_ = 'softmax'\n",
    "AUC Score: .74"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = MLPClassifier(activation='tanh',\n",
    "                    solver='adam', \n",
    "                    alpha=1e-5,\n",
    "                    hidden_layer_sizes=(250, 375, 750, 250, 50, 125), \n",
    "                    random_state=1,\n",
    "                    early_stopping=True,\n",
    "                    max_iter=500,\n",
    "                    learning_rate='adaptive')\n",
    "reg.out_activation_ = 'softmax'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MLPClassifier(activation='tanh', alpha=1e-05, batch_size='auto', beta_1=0.9,\n",
       "              beta_2=0.999, early_stopping=True, epsilon=1e-08,\n",
       "              hidden_layer_sizes=(250, 375, 750, 250, 50, 125),\n",
       "              learning_rate='adaptive', learning_rate_init=0.001, max_fun=15000,\n",
       "              max_iter=500, momentum=0.9, n_iter_no_change=10,\n",
       "              nesterovs_momentum=True, power_t=0.5, random_state=1,\n",
       "              shuffle=True, solver='adam', tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=False, warm_start=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.fit(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def auc(X, Y):\n",
    "    try:                  # compute 'response' (soft binary classification score)\n",
    "        soft = reg.predict_proba(X)[:,1]  # p(class = 2nd)\n",
    "    except (AttributeError, IndexError):  # or we can use 'hard' binary prediction if soft is unavailable\n",
    "        soft = reg.predict(X)\n",
    "\n",
    "    n,d = twod(soft).shape             # ensure soft is the correct shape\n",
    "    soft = soft.flatten() if n==1 else soft.T.flatten()\n",
    "\n",
    "    indices = np.argsort(soft)         # sort data by score value\n",
    "    Y = Y[indices]\n",
    "    sorted_soft = soft[indices]\n",
    "\n",
    "    # compute rank (averaged for ties) of sorted data\n",
    "    dif = np.hstack( ([True],np.diff(sorted_soft)!=0,[True]) )\n",
    "    r1  = np.argwhere(dif).flatten()\n",
    "    r2  = r1[0:-1] + 0.5*(r1[1:]-r1[0:-1]) + 0.5\n",
    "    rnk = r2[np.cumsum(dif[:-1])-1]\n",
    "\n",
    "    # number of true negatives and positives\n",
    "    n0,n1 = sum(Y == 0), sum(Y == 1)\n",
    "\n",
    "    if n0 == 0 or n1 == 0:\n",
    "        raise ValueError('Data of both class values not found')\n",
    "\n",
    "    # compute AUC using Mann-Whitney U statistic\n",
    "    result = (np.sum(rnk[Y == 1]) - n1 * (n1 + 1.0) / 2.0) / n1 / n0\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8282433523903281"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(Xtr, Ytr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.732008026921417"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc(Xte, Yte)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xleader = np.genfromtxt('Data/X_test.txt', delimiter=None)\n",
    "Xleader = scaler.transform(Xleader)\n",
    "predict_test = reg.predict_proba(Xleader)\n",
    "Yte = np.vstack((np.arange(Xleader.shape[0]), predict_test[:,1])).T\n",
    "np.savetxt('Y_submit.txt',Yte,'%d, %.2f',header='ID,Prob1',comments='',delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
